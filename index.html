<html>
  <head>
    <script src="https://cdn.jsdelivr.net/npm/@tensorflow/tfjs/dist/tf.min.js"> </script>
    <script src="https://cdn.jsdelivr.net/npm/@tensorflow/tfjs-backend-wasm/dist/tf-backend-wasm.min.js"> </script>
    <script src="https://cdn.jsdelivr.net/npm/@tensorflow-models/body-pix/dist/body-pix.min.js"></script>

    <script>
      console.log(tf.version);
      tf.setBackend('wasm').then(async () => {

        const net = await bodyPix.load();

// input source
const $video = document.querySelector("video");
// output source
const $destCanvas = document.querySelector("canvas");

const stream = await navigator.mediaDevices.getUserMedia({ video: true });
$video.srcObject = stream;

document.querySelector("button").onclick = async () => {
  // THESE LINES ARE REQUIRED!
  $video.width = $destCanvas.width = $video.videoWidth;
  $video.height = $destCanvas.height = $video.videoHeight;

  const destCtx = $destCanvas.getContext("2d");
  $destCanvas.style.backgroundImage = "url(./bg.jpg)";
  $destCanvas.style.backgroundSize = "contain";

  // to remove background, need another canvas
  const $tempCanvas = document.createElement("canvas");
  $tempCanvas.width = $video.videoWidth;
  $tempCanvas.height = $video.videoHeight;
  const tempCtx = $tempCanvas.getContext("2d");

  (async function loop() {
    requestAnimationFrame(loop);

    // create mask on temp canvas
    const segmentation = await net.segmentPerson($video);
    const mask = bodyPix.toMask(segmentation);
    tempCtx.putImageData(mask, 0, 0);

    // draw original
    destCtx.drawImage($video, 0, 0, $destCanvas.width, $destCanvas.height);

    // then overwrap, masked area will be removed
    destCtx.save();
    destCtx.globalCompositeOperation = "destination-out";
    destCtx.drawImage($tempCanvas, 0, 0, $destCanvas.width, $destCanvas.height);
    destCtx.restore();
  })();
};

        // let img = tf.browser.fromPixels(document.getElementById('img'))
        //   .resizeBilinear([224, 224])
        //   .expandDims(0)
        //   .toFloat();

        // let model = await tf.loadGraphModel(
        //   'https://tfhub.dev/google/imagenet/mobilenet_v2_100_224/classification/2',
        //   {fromTFHub: true});
        // const y = model.predict(img);

        // y.print();

        // // Notice there is no 'import' statement. 'tf' is available on the index-page
        // // because of the script tag above.

        // // Define a model for linear regression.
        // const model = tf.sequential();
        // model.add(tf.layers.dense({units: 1, inputShape: [1]}));

        // // Prepare the model for training: Specify the loss and the optimizer.
        // model.compile({loss: 'meanSquaredError', optimizer: 'sgd'});

        // // Generate some synthetic data for training.
        // const xs = tf.tensor2d([1, 2, 3, 4], [4, 1]);
        // const ys = tf.tensor2d([1, 3, 5, 7], [4, 1]);

        // // Train the model using the data.
        // model.fit(xs, ys).then(() => {
        //   // Use the model to do inference on a data point the model hasn't seen before:
        //   // Open the browser devtools to see the output
        //   model.predict(tf.tensor2d([5], [1, 1])).print();
        // });
      });
    </script>
  </head>

  <body>
    <img id="img" src="./stay-home-save-lives-april-17-copy-6753651837108784-law.gif" />
  </body>
</html>